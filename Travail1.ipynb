{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travail pratique 1 - IFT 3700\n",
    "##### Remis le 22 novembre 2020 par Rym Bach et Laurier Lavoie-Giasson\n",
    "## Introduction\n",
    "Dans le cadre de ce travail, on s'intéresse à la précision des différentes techniques de classification vues en classe, et de comparer son niveau en utilisant la distance euclidienne ainsi que [...]\n",
    "## Code\n",
    "### Installation des packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/laurier/.local/lib/python3.7/site-packages (4.51.0)\n",
      "Collecting scikit-image\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/ee/753ea56fda5bc2a5516a1becb631bf5ada593a2dd44f21971a13a762d4db/scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.5MB 79kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/laurier/.local/lib/python3.7/site-packages (from scikit-image) (7.2.0)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/8c/166c88fcbe3b3632dcf93a106f6d13892b1a2b822b61eb7cd9a5ab68b259/tifffile-2020.10.1-py3-none-any.whl (152kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/laurier/.local/lib/python3.7/site-packages (from scikit-image) (3.3.2)\n",
      "Collecting networkx>=2.0 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/cd/dc52755d30ba41c60243235460961fc28022e5b6731f16c268667625baea/networkx-2.5-py3-none-any.whl (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 662kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 325kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.4MB 238kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /home/laurier/.local/lib/python3.7/site-packages (from scikit-image) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /home/laurier/.local/lib/python3.7/site-packages (from scikit-image) (1.19.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/laurier/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/laurier/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/laurier/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.7.3)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/laurier/.local/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3/dist-packages (from networkx>=2.0->scikit-image) (4.3.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
      "Installing collected packages: tifffile, networkx, imageio, PyWavelets, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 imageio-2.9.0 networkx-2.5 scikit-image-0.17.2 tifffile-2020.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et prétraitement des jeux de données d'entraînement et de tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:00<00:00, 709706.12it/s]\n",
      "  1%|          | 329/60000 [00:00<00:18, 3288.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des labels pour mnist_train.csv\n",
      "Extraction des points de données pour mnist_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:18<00:00, 3219.59it/s]\n",
      "100%|██████████| 60000/60000 [00:01<00:00, 40647.50it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 735778.27it/s]\n",
      "  3%|▎         | 332/10000 [00:00<00:02, 3318.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des labels pour mnist_test.csv\n",
      "Extraction des points de données pour mnist_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3348.11it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 42547.43it/s]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "CONST_N_DIM=784\n",
    "\n",
    "def preprocessing(aX, an_dimensions=CONST_N_DIM):\n",
    "    #cette fonction sera utilisée pour le prétraitement des données du jeu de données.\n",
    "    \n",
    "    ret_val = np.array([np.round(np.divide(aX[i], 255.0)) for i in tqdm(range(len(aX)))])\n",
    "    \n",
    "    #application de PCA pour la réduction de dimensionalité\n",
    "    #pca = PCA(n_components=an_dimensions)\n",
    "    #ret_val = pca.fit_transform(X_rounded)\n",
    "    return ret_val\n",
    "    \n",
    "def readMNIST(afilename, an_dimensions=CONST_N_DIM):\n",
    "    #cette fonction lit le fichier de MNIST à l'emplacement fourni et retourne le jeu de\n",
    "    #données sur lequel on a appliqué la fonction de prétraitement\n",
    "    data = open(afilename)\n",
    "    csv_file = csv.reader(data)\n",
    "    data_points = [row for row in csv_file] #pour enlever les headers\n",
    "    data_points.pop(0)\n",
    "    #valeurs Y de taille 1 (labels)\n",
    "    print(\"Extraction des labels pour\", afilename)\n",
    "    Y = np.array([int(data_points[i][0]) for i in tqdm(range(len(data_points)))])\n",
    "    \n",
    "    #vecteurs X de taille 784 (arrondis à l'entier le plus près)\n",
    "    print(\"Extraction des points de données pour\", afilename)\n",
    "    X = np.array([[int(j) for j in data_points[i][1:]] for i in tqdm(range(len(data_points)))])\n",
    "    X = X.reshape((len(Y),784))\n",
    "    \n",
    "    #on retourne un tuple avec les vecteurs x et les valeurs y\n",
    "    return (preprocessing(X, an_dimensions),Y)\n",
    "\n",
    "XY_train = readMNIST('mnist_train.csv', CONST_N_DIM)\n",
    "X_train = XY_train[0]\n",
    "Y_train = XY_train[1]\n",
    "\n",
    "XY_test = readMNIST('mnist_test.csv', CONST_N_DIM)\n",
    "X_test = XY_test[0]\n",
    "Y_test = XY_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Sanity Check_\n",
    "Ici on regarde si les données sont encore \"saines\", c'est à dire si on peut afficher la première lettre du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0].reshape((28,28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place de la métrique à utiliser\n",
    "\n",
    "Soit $X = \\begin{pmatrix}x_{11} & ... & x_{1n}\\\\ ... & ... & ... \\\\ x_{n1} & ... & x_{nn}\\end{pmatrix}$, le caractère en question. On calculera d'abord $M_{00}, M_{01}$ et $M_{10}$.\n",
    "\n",
    "\\begin{align}\n",
    "    M_{ij} = \\sum_{k=1}^{d_1}\\sum_{\\ell}^{d_2}x_{k\\ell}k^i\\cdot\\ell^j\n",
    "\\end{align}\n",
    "\n",
    "On calculera alors le centroïde de l'image $\\{\\bar{x},\\bar{y}\\} = \\{\\frac{M_{10}}{M_{00}}, \\frac{M_{01}}{M_{00}}\\}$, ainsi que les moments centraux $\\mu_{00}, \\mu_{20}, \\mu_{02}, \\mu_{11}, \\mu_{30}, \\mu_{03}, \\mu_{21}$ et $\\mu_{12}$\n",
    "\n",
    "\\begin{align}\n",
    "    \\mu_{ij} = \\sum_{k=1}^{d_1}\\sum_{\\ell=1}^{d_2}x_{k\\ell}\\cdot(k-\\bar{x})^i\\cdot(\\ell−\\bar{y})^j)\n",
    "\\end{align}\n",
    "\n",
    "Pour finir, on calculera la similarité des points en comparant la distance euclidienne entre les vecteurs contenant leurs moments invariants $\\eta_{20}, \\eta_{02}, \\eta_{11}, \\eta_{30}, \\eta_{03}, \\eta_{21}$ et $\\eta_{12}$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\eta_{ij} = \\frac{\\mu_{ij}}{\\mu_{00}^{(1+\\frac{i+j}{2})}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import moments, moments_central\n",
    "\n",
    "#on définit la fonction de similarité à utiliser\n",
    "def moment_distance(ax_1, ax_2):\n",
    "    x_1=ax_1.reshape((28,28))\n",
    "    x_2=ax_2.reshape((28,28))\n",
    "    m=moments(x_1)\n",
    "    mu=moments_central(x_1)\n",
    "    \n",
    "    mij_differences=np.array([computeMij(ax_1, ij[0], ij[1])-computeMij(ax_2, ij[0], ij[1]) for ij in ij_list])\n",
    "    dist = np.sqrt(np.sum(np.power(mij_differences,2)))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la lettre apparait bel et bien, on peut donc considérer que le jeu de données a été correctement chargé\n",
    "### Classification en utilisant l'algorithme K-médoïdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Classification KMeans\n",
    "#en utilisant plusieurs valeurs de K (8,9,10, 11, ...)\n",
    "#et en calculant le score silhouette à chaque valeur de K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification en utilisant l'algorithme des K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "from multiprocessing.sharedctypes import Array\n",
    "import math\n",
    "#on va utiliser ici du multi-processing pour travailler autour du GIL de Python,\n",
    "#on va démarrer plusieurs processus et travailler sur des variables partagées\n",
    "\n",
    "def fit_and_score(aX_train, aY_train, aX_test, aY_test, ak, aAccuracy_shared_array):\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=ak)\n",
    "    classifier.fit(aX_train, aY_train)\n",
    "    aAccuracy_shared_array[(ak-1)/2] = classifier.score(aX_test, aY_test)\n",
    "    return aAccuracy_shared_array[ak]\n",
    "\n",
    "\n",
    "\n",
    "def classify_KNN(aX_train, aY_train, aX_test, aY_test, max_neighbors, multi_process=True):\n",
    "    if multi_process:\n",
    "        #on crée un tableau partagé de doubles \"primitifs\" de C pour les résultats\n",
    "        aX_train_shared=Array('d', aX_train.shape[0]*aX_train.shape[1])\n",
    "        #on le passe à Numpy pour utilisation à travers l'interface \"buffer\"\n",
    "        aX_train_mp=np.frombuffer(aX_train_shared.get_obj()).reshape(aX_train.shape)\n",
    "        #on copie les valeurs de l'argument dans le tableau partagé\n",
    "        np.copyto(aX_train_mp, aX_train)\n",
    "        \n",
    "        aY_train_shared=Array('d', aY_train.size)\n",
    "        aY_train_mp=np.frombuffer(aY_train_shared.get_obj())\n",
    "        np.copyto(aY_train_mp, aY_train)\n",
    "        \n",
    "        \n",
    "        aX_test_shared=Array('d', aX_test.shape[0]*aX_test.shape[1])\n",
    "        aX_test_mp=np.frombuffer(aX_test_shared.get_obj()).reshape(aX_test.shape)\n",
    "        np.copyto(aX_test_mp, aX_test)\n",
    "        \n",
    "        \n",
    "        aY_test_shared=Array('d', aY_test.size)\n",
    "        aY_test_mp=np.frombuffer(aY_test_shared.get_obj())\n",
    "        np.copyto(aY_test_mp, aY_test)\n",
    "        \n",
    "        #initialisation des K impairs\n",
    "        k_range = np.add(np.multiply(np.array(range(math.floor(max_neighbors/2.0))), 2),1)\n",
    "        k_range.size\n",
    "        \n",
    "        #on crée un tableau partagé de doubles \"primitifs\" de C pour stocker la précision des modèles\n",
    "        accuracy_array = Array('d', len(k_range))\n",
    "        accuracy = np.frombuffer(accuracy_array.get_obj())\n",
    "        #on initialise les valeurs à zéro\n",
    "        np.copyto(accuracy, np.zeros(len(k_range)))\n",
    "        \n",
    "        processes = []\n",
    "        \n",
    "        for k in k_range:\n",
    "            if k % 2 != 0:\n",
    "                #spawn un processus pour calculer, qui lira la mémoire partagée\n",
    "                myprocess=Process(target=fit_and_score, args=(aX_train_mp, aY_train_mp, aX_test_mp, aY_test_mp, k, accuracy))\n",
    "                processes.append(myprocess)\n",
    "                myprocess.start()\n",
    "        for i in tqdm(range(len(processes))):\n",
    "            myprocess=processes[i]\n",
    "            #join le processus pour arrêter l'exécution jusqu'à temps que les calculs soient terminés\n",
    "            myprocess.join()\n",
    "            del myprocess\n",
    "        #retourner les paires de K et de précision\n",
    "        return np.array([np.array(k_range), accuracy])\n",
    "    else:\n",
    "        classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "        classifier.fit(aX_train, aY_train)\n",
    "        print(classifier.score(aX_test, aY_test))\n",
    "        #TODO changer ceci ASAP. Dois aller dormir lol\n",
    "        \n",
    "    \n",
    "resultats_KNN = classify_KNN(X_train, Y_train, X_test, Y_test, 15, True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resultats_KNN[0], resultats_KNN[1])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Précision de la classification en fonction de k');\n",
    "plt.xticks(np.arange(min(resultats_KNN[0]), max(resultats_KNN[1])+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
