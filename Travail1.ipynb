{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travail pratique 1 - IFT 3700\n",
    "##### Remis le 22 novembre 2020 par Rym Bach et Laurier Lavoie-Giasson\n",
    "## Introduction\n",
    "Dans le cadre de ce travail, on s'intéresse à la précision des différentes techniques de classification vues en classe, et de comparer son niveau en utilisant la distance euclidienne ainsi que [...]\n",
    "## Code\n",
    "### Installation des packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et prétraitement des jeux de données d'entraînement et de tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:00<00:00, 775194.11it/s]\n",
      "  0%|          | 287/60000 [00:00<00:20, 2864.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des labels pour mnist_train.csv\n",
      "Extraction des points de données pour mnist_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:20<00:00, 2965.43it/s]\n",
      "100%|██████████| 60000/60000 [00:01<00:00, 38879.79it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 785876.97it/s]\n",
      "  3%|▎         | 336/10000 [00:00<00:02, 3359.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des labels pour mnist_test.csv\n",
      "Extraction des points de données pour mnist_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3100.42it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 45289.58it/s]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "CONST_N_DIM=784\n",
    "\n",
    "def preprocessing(aX, an_dimensions=CONST_N_DIM):\n",
    "    #cette fonction sera utilisée pour le prétraitement des données du jeu de données.\n",
    "    \n",
    "    ret_val = np.array([np.round(np.divide(aX[i], 255.0)) for i in tqdm(range(len(aX)))])\n",
    "    #application de PCA pour la réduction de dimensionalité\n",
    "    #pca = PCA(n_components=an_dimensions)\n",
    "    #ret_val = pca.fit_transform(X_rounded)\n",
    "    return ret_val\n",
    "    \n",
    "def readMNIST(afilename, an_dimensions=CONST_N_DIM):\n",
    "    #cette fonction lit le fichier de MNIST à l'emplacement fourni et retourne le jeu de\n",
    "    #données sur lequel on a appliqué la fonction de prétraitement\n",
    "    data = open(afilename)\n",
    "    csv_file = csv.reader(data)\n",
    "    data_points = [row for row in csv_file] #pour enlever les headers\n",
    "    data_points.pop(0)\n",
    "    #valeurs Y de taille 1 (labels)\n",
    "    print(\"Extraction des labels pour\", afilename)\n",
    "    Y = np.array([int(data_points[i][0]) for i in tqdm(range(len(data_points)))])\n",
    "    \n",
    "    #vecteurs X de taille 784 (arrondis à l'entier le plus près)\n",
    "    print(\"Extraction des points de données pour\", afilename)\n",
    "    X = np.array([[int(j) for j in data_points[i][1:]] for i in tqdm(range(len(data_points)))])\n",
    "    X = X.reshape((len(Y),784))\n",
    "    \n",
    "    #on retourne un tuple avec les vecteurs x et les valeurs y\n",
    "    return (preprocessing(X, an_dimensions),Y)\n",
    "\n",
    "XY_train = readMNIST('mnist_train.csv', CONST_N_DIM)\n",
    "X_train = XY_train[0]\n",
    "Y_train = XY_train[1]\n",
    "\n",
    "XY_test = readMNIST('mnist_test.csv', CONST_N_DIM)\n",
    "X_test = XY_test[0]\n",
    "Y_test = XY_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Sanity Check_\n",
    "Ici on regarde si les données sont encore \"saines\", c'est à dire si on peut afficher la première lettre du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape((28,28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place de la métrique à utiliser\n",
    "\n",
    "Soit $X = \\begin{pmatrix}x_{11} & ... & x_{1n}\\\\ ... & ... & ... \\\\ x_{n1} & ... & x_{nn}\\end{pmatrix}$, le caractère en question. On calculera d'abord $M_{00}, M_{01}$ et $M_{10}$.\n",
    "\n",
    "\\begin{align}\n",
    "    M_{ij} = \\sum_{k=1}^{d_1}\\sum_{\\ell}^{d_2}x_{k\\ell}k^i\\cdot\\ell^j\n",
    "\\end{align}\n",
    "\n",
    "On calculera alors le centroïde de l'image $\\{\\bar{x},\\bar{y}\\} = \\{\\frac{M_{10}}{M_{00}}, \\frac{M_{01}}{M_{00}}\\}$, suivi des moments centraux $\\mu_{00}, \\mu_{20}, \\mu_{02}, \\mu_{11}, \\mu_{30}, \\mu_{03}, \\mu_{21}$ et $\\mu_{12}$\n",
    "\n",
    "\\begin{align}\n",
    "    \\mu_{ij} = \\sum_{k=1}^{d_1}\\sum_{\\ell=1}^{d_2}x_{k\\ell}\\cdot(k-\\bar{x})^i\\cdot(\\ell−\\bar{y})^j)\n",
    "\\end{align}\n",
    "\n",
    "Pour finir, on calculera la similarité des points en comparant la distance euclidienne entre les vecteurs contenant leurs moments invariants $\\eta_{20}, \\eta_{02}, \\eta_{11}, \\eta_{30}, \\eta_{03}, \\eta_{21}$ et $\\eta_{12}$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\eta_{ij} = \\frac{\\mu_{ij}}{\\mu_{00}^{(1+\\frac{i+j}{2})}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1.5 2.  2.5]\n",
      " [1.5 2.  2.5 3. ]\n",
      " [2.  2.5 3.  3.5]\n",
      " [2.5 3.  3.5 4. ]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import moments, moments_central\n",
    "\n",
    "#matrice des exposants à appliquer à mu00, pour accélérer les calculs en les faisant faire en série par Numpy\n",
    "muij_exponents=np.array([[1+(i+j)/2.0 for j in range(4)] for i in range(4)])\n",
    "print(muij_exponents)\n",
    "\n",
    "#matrice des facteurs de eta_ij, pour enlever les valeurs \"non désirées\" à la matrice \"finale\" des eta_ij\n",
    "eta_ij_selected=np.array([\n",
    "    [0,0,1,1],\n",
    "    [0,1,1,0],\n",
    "    [1,1,0,0],\n",
    "    [1,0,0,0]\n",
    "])\n",
    "\n",
    "#fonction qui calcule eta_ij pour un vecteur X de taille 784 donné\n",
    "def compute_eta_ij(ax):\n",
    "    x = ax.reshape((28,28))\n",
    "    m = moments(x)\n",
    "    centroid = (m[1,0]/m[0,0], m[0,1]/m[0,0])\n",
    "    mu = moments_central(x, centroid)\n",
    "    #print(mu[0,0])\n",
    "    #on multiplie par eta_ij_selected, pour soustraire les valeurs nécessaires\n",
    "    eta = np.multiply(mu, np.power(mu[0,0], muij_exponents))\n",
    "    return np.array([eta[2,0], eta[0,2], eta[1,1], eta[3,0], eta[0,3], eta[2,1], eta[1,2]])\n",
    "#on définit la fonction de similarité à utiliser\n",
    "def moment_distance(ax_1, ax_2):\n",
    "    return np.linalg.norm(compute_eta_ij(ax_1)-compute_eta_ij(ax_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconvénient lors de l'utilisation de cette métrique de façon conventionnelle - Complexité\n",
    "En ne faisant que spécifier la métrique dans le contructeur des différents classificateurs, on augmente drastiquement la complexité. En effet, pour les $n^2$ paires de points, pour calculer la matrice des distances entre, on effectue 1 appel de la fonction compute_eta_ij par point, pour un total de 2n^2. Comme la matrice est symétrique, on peut considérer que l'on appelle $n^2$ fois la fonction. Cependant, la complexité du calcul des $\\eta_{ij}$ est bien plus grande que celle de la distance euclidienne! Il convient donc d'adapter la méthode de calcul pour réduire la complexité.\n",
    "\n",
    "### Solution - _precomputation_\n",
    "Évidemment, une fois que l'on a exécuté compute_eta_ij pour un point du jeu de données, on peut stocker la valeur de retour dans une liste. Puisque la métrique proposée utilise la distance euclidienne à l'intérieur, on peut donc simplement faire un précalcul des $\\eta_{ij}$ nécessaires pour la métrique, et les stocker dans une liste. Cela nous permettra de classifier le jeu de données de la même façon que l'on l'aurait fait dans le jeu de données d'origine.\n",
    "\n",
    "Par contre, pour pouvoir classer une donnée, on devra d'abord effectuer la transformation pour obtenir les $\\eta_{ij}$.\n",
    "\n",
    "La cellule ci-dessous effectue le précalcul nécessaire à la métrique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 871/60000 [00:00<00:14, 4201.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "précalcul des eta_ij pour le jeu de données d'entraînement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:12<00:00, 4717.49it/s]\n",
      "  5%|▍         | 477/10000 [00:00<00:01, 4768.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "précalcul des eta_ij pour le jeu de données de tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4844.45it/s]\n"
     ]
    }
   ],
   "source": [
    "def precompute_eta_ij(aX):\n",
    "    return np.array([compute_eta_ij(x) for x in tqdm(aX)])\n",
    "\n",
    "print(\"précalcul des eta_ij pour le jeu de données d'entraînement\")\n",
    "X_train_etaij = precompute_eta_ij(X_train)\n",
    "print(\"précalcul des eta_ij pour le jeu de données de tests\")\n",
    "X_test_etaij = precompute_eta_ij(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification en utilisant l'algorithme K-médoïdes\n",
    "\n",
    "\n",
    "L'algorithme des k-médoïdes est un algorithme de partitionnement plus robuste vis-à-vis des données aberrantes \n",
    " que celui des k-means , l'algorithme des k-médoïdes minimise l'erreur quadratique \n",
    "moyenne qui est la distance entre les points de la classe et le point central  on va \n",
    "donc l'appliquer sur nos donnees \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from pyclustering.cluster.kmedoids import kmedoids \n",
    "\n",
    "\n",
    " \n",
    "#cette méthode utilisée pour classifier les données est la bonne. Il faut \n",
    "def classify_fmedoide(X_train, Y_train):\n",
    "    scores = []\n",
    "    k_range = range(2,15)\n",
    "    for k in k_range:\n",
    "        y_pred = KMeans(n_clusters=k).fit_predict(X_train)\n",
    "        scores.append(silhouette_score(X_train, y_pred))\n",
    "\n",
    "    plt.plot(k_range, scores)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Score silhouette')\n",
    "    plt.title('Score silhouette en fonction de k')\n",
    "\n",
    "return np.array([k_range, scores])\n",
    "\n",
    "#cette fonction ne semble pas nécessaire\n",
    "def kmedoide_Euclidienne () :               \n",
    "    MatrixDeucli = euclidean_distances(X_train)\n",
    "    tab =[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    #kmedoidseuclidienne = MatrixDeucli, tab, data_type='distance_matrix')\n",
    "    kmedoidseuclidienne.process()\n",
    "    euclidienne_medoids = kmedoidseuclidienne.get_medoids()\n",
    "    clusters_euclidienne = kmedoidseuclidienne.get_clusters()\n",
    "    #j'ai réindenté ceci pour que ça \"compile\"fonctionne bien\n",
    "    return np.array([euclidienne_medoids,clusters_euclidienne])  \n",
    "\n",
    "#cette fonction n'est pas nécessaire non plus\n",
    "def kmedoide_distance ()     :               \n",
    "    matrixSimi = np.array(copy.deepcopy(Y_train).astype(np.float64)\n",
    "    tab =[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    kmedoidsdistance = kmedoids(matrixSimi, tab, data_type='distance_matrix')\n",
    "    kmedoidsdistance.process()\n",
    "    distancemedoids = kmedoidsdistance.get_medoids()\n",
    "    clustersdistance = kmedoidsdistance.get_clusters()\n",
    "    #réindentation ici aussi\n",
    "    return np.array([kmedoidsdistance,clustersdistance]) \n",
    "\n",
    "#le travail n'est pas d'implémenter les algorithmes de classification, c'est plutôt d'utiliser ce que\n",
    "#scikit-learn fournit de pré-construit pour pouvoir faire abstraction de l'algorithme (de présumer que\n",
    "#l'algorithme fonctionnera, sans se poser de question sur les technicalités de ce qui se passe derrière).\n",
    "#essaie de regarder des exemples de classification avec KMeans de scikit-learn sur Internet, ça devrait t'aider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification en utilisant l'algorithme des K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_test_etaij' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a3ec77df544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m#resultats_KNN = classify_KNN(X_train[1:3000], Y_train[1:3000], X_test[1:3000], Y_test[1:3000], 15, True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultats_KNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mresultats_KNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_etaij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_etaij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_etaij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test_etaij' is not defined"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "from multiprocessing.sharedctypes import Array\n",
    "import math\n",
    "#on va utiliser ici du multi-processing pour travailler autour du GIL de Python,\n",
    "#on va démarrer plusieurs processus et travailler sur des variables partagées\n",
    "\n",
    "def fit_and_score(aX_train, aY_train, aX_test, aY_test, ak, aAccuracy_shared_array):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=ak)\n",
    "    classifier.fit(aX_train, aY_train)\n",
    "    aAccuracy_shared_array[ak] = classifier.score(aX_test, aY_test)\n",
    "    return aAccuracy_shared_array[ak]\n",
    "\n",
    "def classify_KNN(aX_train, aY_train, aX_test, aY_test, max_neighbors, multi_process=True):\n",
    "    if multi_process:\n",
    "        #on crée un tableau partagé de doubles \"primitifs\" de C pour les résultats\n",
    "        aX_train_shared=Array('d', aX_train.shape[0]*aX_train.shape[1])\n",
    "        #on le passe à Numpy pour utilisation à travers l'interface \"buffer\"\n",
    "        aX_train_mp=np.frombuffer(aX_train_shared.get_obj()).reshape(aX_train.shape)\n",
    "        #on copie les valeurs de l'argument dans le tableau partagé\n",
    "        np.copyto(aX_train_mp, aX_train)\n",
    "        \n",
    "        aY_train_shared=Array('d', aY_train.size)\n",
    "        aY_train_mp=np.frombuffer(aY_train_shared.get_obj())\n",
    "        np.copyto(aY_train_mp, aY_train)\n",
    "        \n",
    "        \n",
    "        aX_test_shared=Array('d', aX_test.shape[0]*aX_test.shape[1])\n",
    "        aX_test_mp=np.frombuffer(aX_test_shared.get_obj()).reshape(aX_test.shape)\n",
    "        np.copyto(aX_test_mp, aX_test)\n",
    "        \n",
    "        \n",
    "        aY_test_shared=Array('d', aY_test.size)\n",
    "        aY_test_mp=np.frombuffer(aY_test_shared.get_obj())\n",
    "        np.copyto(aY_test_mp, aY_test)\n",
    "        \n",
    "        #initialisation des K impairs\n",
    "        k_range = range(max_neighbors)\n",
    "        \n",
    "        #on crée un tableau partagé de doubles \"primitifs\" de C pour stocker la précision des modèles\n",
    "        accuracy_array = Array('d', len(k_range))\n",
    "        accuracy = np.frombuffer(accuracy_array.get_obj())\n",
    "        #on initialise les valeurs à zéro\n",
    "        np.copyto(accuracy, np.zeros(len(k_range)))\n",
    "        \n",
    "        processes = []\n",
    "        \n",
    "        for k in k_range:\n",
    "            if k % 2 != 0:\n",
    "                #spawn un processus pour calculer, qui lira la mémoire partagée\n",
    "                myprocess=Process(target=fit_and_score, args=(aX_train_mp, aY_train_mp, aX_test_mp, aY_test_mp, k, accuracy))\n",
    "                processes.append(myprocess)\n",
    "                myprocess.start()\n",
    "        for i in tqdm(range(len(processes))):\n",
    "            myprocess=processes[i]\n",
    "            #join le processus pour arrêter l'exécution jusqu'à temps que les calculs soient terminés\n",
    "            myprocess.join()\n",
    "            del myprocess\n",
    "        #retourner les paires de K et de précision\n",
    "        return np.array([np.array(k_range), accuracy])\n",
    "    else:\n",
    "        for k in range(max_neighbors):\n",
    "            if k % 2 != 0:\n",
    "                classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "                classifier.fit(aX_train, aY_train)\n",
    "                print(classifier.score(aX_test, aY_test))\n",
    "        \n",
    "\n",
    "#resultats_KNN = classify_KNN(X_train[1:3000], Y_train[1:3000], X_test[1:3000], Y_test[1:3000], 15, True)\n",
    "print(resultats_KNN)\n",
    "resultats_KNN = classify_KNN(X_train_etaij, Y_train, X_test_etaij, Y_test, 15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(resultats_KNN[0], resultats_KNN[1])\n",
    "#plt.xlabel('k')\n",
    "#plt.ylabel('Précision')\n",
    "#plt.title('Précision de la classification en fonction de k');\n",
    "#plt.xticks(np.arange(min(resultats_KNN[0]), max(resultats_KNN[1])+1, 1.0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
